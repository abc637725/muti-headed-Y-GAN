import os
import sys
import io
import sys,  time
import glob
import pickle
import argparse
import threading
import queue
import traceback
import numpy as np

import PIL.Image
import h5py 
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn as nn
from torch import autograd
from torch.autograd import Variable
from models.base_model import *
from torch.autograd import Variable

import matplotlib.pyplot as plt
import imageio
import torchvision.transforms as transforms
import random
from PIL import Image, ImageEnhance
from pylab import *
from scipy.ndimage import filters

import scipy.misc
import torch.nn as nn
from torch.utils.data import Dataset

def main_line(img_in):
    img_in=np.squeeze(img_in, 0)
    img_in= img_in.transpose(1,2,0)
    img_in = np.uint8(img_in)
    img_in = Image.fromarray(img_in)
    im = img_in.convert('L')   #PIL有九种不同模式: 1，L，P，RGB，RGBA，CMYK，YCbCr，I，F。
    im = np.array(im)
    img_in=xdog(im)
    img_in=img_in[np.newaxis,np.newaxis :]
    return  img_in

def xdog_o(image):
    Gamma = 0.92
    Phi = 200
    Epsilon = 1
    k = 2.5
    Sigma =0.5
    image = array(ImageEnhance.Sharpness(image).enhance(3.0))
    im2 = filters.gaussian_filter(image, Sigma)
    im3 = filters.gaussian_filter(image, Sigma* k)
    differencedIm2 = im2 - (Gamma * im3)
    (x, y) = shape(im2)
    for i in range(x):
        for j in range(y):                
            if differencedIm2[i, j] < Epsilon:
                differencedIm2[i, j] = 0
            else:
                differencedIm2[i, j] = 255
    return differencedIm2


def xdog(image, epsilon=0.5, phi=10, k=1.4, Gamma=1, sigma=0.5):
    
    image = filters.gaussian_filter(image, 0.7)
    im2 = filters.gaussian_filter(image, sigma)
    im3 = filters.gaussian_filter(image, sigma*k)

    D = im2 - Gamma*im3

    U = D/255
    
    for i in range(0,len(U)):
        for j in range(0,len(U[0])):
            U[i][j] = abs(1-U[i][j])
            
    for i in range(0, len(U)):
        for j in range(0, len(U[0])):
            if U[i][j] >= epsilon:
                U[i][j] = 1
            else:
                ht = np.tanh(phi*(U[i][j] - epsilon))
                U[i][j] = 1 + ht

    return U*255

def main_gray(img_in):

    img_in=np.squeeze(img_in, 0)
    img_in= img_in.transpose(1,2,0)
    img_in = np.uint8(img_in)
    img_in = Image.fromarray(img_in)
    im = img_in.convert('L')   #PIL有九种不同模式: 1，L，P，RGB，RGBA，CMYK，YCbCr，I，F。
    im = array(im)
    im=im[np.newaxis,np.newaxis, :]
    return  im

def main_TPS(img_in):
    img_in=np.squeeze(img_in, 0)
    img_in= img_in.transpose(1,2,0)
    img_in = np.uint8(img_in)
    img_in = Image.fromarray(img_in)
    im = array(im)
    im=im[np.newaxis,np.newaxis, :]
    return  im
    
class LocalizationNetwork(nn.Module):
    """ Localization Network of RARE, which predicts C' (K x 2) from I (I_width x I_height) """

    def __init__(self, F, I_channel_num):
        super(LocalizationNetwork, self).__init__()
        self.F = F
        self.I_channel_num = I_channel_num
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=self.I_channel_num, out_channels=64, kernel_size=3, stride=1, padding=1,
                      bias=False), nn.BatchNorm2d(64), nn.ReLU(True),
            nn.MaxPool2d(2, 2),  # batch_size x 64 x I_height/2 x I_width/2
            nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128), nn.ReLU(True),
            nn.MaxPool2d(2, 2),  # batch_size x 128 x I_height/4 x I_width/4
            nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(True),
            nn.MaxPool2d(2, 2),  # batch_size x 256 x I_height/8 x I_width/8
            nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512), nn.ReLU(True),
            nn.AdaptiveAvgPool2d(1)  # batch_size x 512
        )

        self.localization_fc1 = nn.Sequential(nn.Linear(512, 256), nn.ReLU(True))
        self.localization_fc2 = nn.Linear(256, self.F * 2)

        # Init fc2 in LocalizationNetwork
        self.localization_fc2.weight.data.fill_(0)
        """ see RARE paper Fig. 6 (a) """
        ctrl_pts_x = np.linspace(-0.7, 0.85, int(F / 2))
        ctrl_pts_y_top = np.linspace(-0.65, -0.7, num=int(F / 2))
        ctrl_pts_y_bottom = np.linspace(0.8, 0.95, num=int(F / 2))
        
        
        ctrl_pts_top = np.stack([ctrl_pts_x, ctrl_pts_y_top], axis=1)
        ctrl_pts_bottom = np.stack([ctrl_pts_x, ctrl_pts_y_bottom], axis=1)
        initial_bias = np.concatenate([ctrl_pts_top, ctrl_pts_bottom], axis=0)
        self.localization_fc2.bias.data = torch.from_numpy(initial_bias).float().view(-1)
        #print(initial_bias)

    def forward(self, batch_I):
        """
        input:     batch_I : Batch Input Image [batch_size x I_channel_num x I_height x I_width]
        output:    batch_C_prime : Predicted coordinates of fiducial points for input batch [batch_size x F x 2]
        """
        batch_size = batch_I.size(0)
        
  
        features = self.conv(batch_I).view(batch_size, -1)
        #print(batch_I.shape,self.conv(batch_I).shape)
        #print(self.conv(batch_I).shape,features.shape) 1  512 1  1 , 1 512
        #print( features,self.localization_fc1(features),self.localization_fc2(self.localization_fc1(features)))
        
        batch_C_prime = self.localization_fc2(self.localization_fc1(features)).view(batch_size, self.F, 2)
        #print(batch_C_prime ) # 1  10  2
        return batch_C_prime


class GridGenerator(nn.Module):
    """ Grid Generator of RARE, which produces P_prime by multipling T with P """

    def __init__(self, F, I_r_size):
        """ Generate P_hat and inv_delta_C for later """
        super(GridGenerator, self).__init__()
        self.eps = 1e-6
        self.I_r_height, self.I_r_width = I_r_size
        self.F = F
        self.C = self._build_C(self.F)  # F x 2
        self.P = self._build_P(self.I_r_width, self.I_r_height)
        self.register_buffer("inv_delta_C", torch.tensor(self._build_inv_delta_C(self.F, self.C)).float())  # F+3 x F+3
        self.register_buffer("P_hat", torch.tensor(self._build_P_hat(self.F, self.C, self.P)).float())  # n x F+3

    def _build_C(self, F):
        """ Return coordinates of fiducial points in I_r; C """
        ctrl_pts_x = np.linspace(-1.0, 1.0, int(F / 2))
        ctrl_pts_y_top = -1 * np.ones(int(F / 2))
        ctrl_pts_y_bottom = np.ones(int(F / 2))
        ctrl_pts_top = np.stack([ctrl_pts_x, ctrl_pts_y_top], axis=1)
        ctrl_pts_bottom = np.stack([ctrl_pts_x, ctrl_pts_y_bottom], axis=1)
        C = np.concatenate([ctrl_pts_top, ctrl_pts_bottom], axis=0)
        return C  # F x 2

    def _build_inv_delta_C(self, F, C):
        """ Return inv_delta_C which is needed to calculate T """
        hat_C = np.zeros((F, F), dtype=float)  # F x F
        for i in range(0, F):
            for j in range(i, F):
                r = np.linalg.norm(C[i] - C[j])
                hat_C[i, j] = r
                hat_C[j, i] = r
        np.fill_diagonal(hat_C, 1)
        hat_C = (hat_C ** 2) * np.log(hat_C)
        # print(C.shape, hat_C.shape)
        delta_C = np.concatenate(  # F+3 x F+3
            [
                np.concatenate([np.ones((F, 1)), C, hat_C], axis=1),  # F x F+3
                np.concatenate([np.zeros((2, 3)), np.transpose(C)], axis=1),  # 2 x F+3
                np.concatenate([np.zeros((1, 3)), np.ones((1, F))], axis=1)  # 1 x F+3
            ],
            axis=0
        )
        inv_delta_C = np.linalg.inv(delta_C)
        return inv_delta_C  # F+3 x F+3

    def _build_P(self, I_r_width, I_r_height):
        I_r_grid_x = (np.arange(-I_r_width, I_r_width, 2) + 1.0) / I_r_width  # self.I_r_width
        I_r_grid_y = (np.arange(-I_r_height, I_r_height, 2) + 1.0) / I_r_height  # self.I_r_height
        P = np.stack(  # self.I_r_width x self.I_r_height x 2
            np.meshgrid(I_r_grid_x, I_r_grid_y),
            axis=2
        )
        return P.reshape([-1, 2])  # n (= self.I_r_width x self.I_r_height) x 2

    def _build_P_hat(self, F, C, P):
        n = P.shape[0]  # n (= self.I_r_width x self.I_r_height)
        P_tile = np.tile(np.expand_dims(P, axis=1), (1, F, 1))  # n x 2 -> n x 1 x 2 -> n x F x 2
        C_tile = np.expand_dims(C, axis=0)  # 1 x F x 2
        P_diff = P_tile - C_tile  # n x F x 2
        rbf_norm = np.linalg.norm(P_diff, ord=2, axis=2, keepdims=False)  # n x F
        rbf = np.multiply(np.square(rbf_norm), np.log(rbf_norm + self.eps))  # n x F
        P_hat = np.concatenate([np.ones((n, 1)), P, rbf], axis=1)
        return P_hat  # n x F+3

    def build_P_prime(self, batch_C_prime):
        """ Generate Grid from batch_C_prime [batch_size x F x 2] """
        batch_size = batch_C_prime.size(0)
        batch_inv_delta_C = self.inv_delta_C.repeat(batch_size, 1, 1)
        batch_P_hat = self.P_hat.repeat(batch_size, 1, 1)
        batch_C_prime_with_zeros = torch.cat((batch_C_prime, torch.zeros(batch_size, 3, 2).float()), dim=1)  # batch_size x F+3 x 2
        batch_T = torch.bmm(batch_inv_delta_C, batch_C_prime_with_zeros)  # batch_size x F+3 x 2
        batch_P_prime = torch.bmm(batch_P_hat, batch_T)  # batch_size x n x 2
        return batch_P_prime  # batch_size x n x 2
    
class TPS_SpatialTransformerNetwork(nn.Module):
    """ Rectification Network of RARE, namely TPS based STN """

    def __init__(self, F=10, I_size = (256,256), I_r_size = (256,256), I_channel_num= 3):
        """ Based on RARE TPS
        input:
            batch_I: Batch Input Image [batch_size x I_channel_num x I_height x I_width]
            I_size : (height, width) of the input image I
            I_r_size : (height, width) of the rectified image I_r
            I_channel_num : the number of channels of the input image I
        output:
            batch_I_r: rectified image [batch_size x I_channel_num x I_r_height x I_r_width]
        """
        super(TPS_SpatialTransformerNetwork, self).__init__()
        self.F = F
        self.I_size = I_size
        self.I_r_size = I_r_size  # = (I_r_height, I_r_width)
        self.I_channel_num = I_channel_num
        self.LocalizationNetwork = LocalizationNetwork(self.F, self.I_channel_num)
        self.GridGenerator = GridGenerator(self.F, self.I_r_size)
        self.transformer_appearance = transforms.Compose([transforms.ToTensor()])

    def forward(self, batch_I):
        batch_I = np.array(batch_I)       
        batch_I =  self.transformer_appearance(batch_I[0].transpose(1, 2, 0))
        batch_I = batch_I[np.newaxis,:, :, :]
        batch_C_prime = self.LocalizationNetwork(batch_I)  # batch_size x K x 2
        build_P_prime = self.GridGenerator.build_P_prime(batch_C_prime)  # batch_size x n (= I_r_width x I_r_height) x 2
        build_P_prime_reshape = build_P_prime.reshape([build_P_prime.size(0), self.I_r_size[0], self.I_r_size[1], 2])
        batch_I_r = F.grid_sample(batch_I, build_P_prime_reshape, padding_mode='border', align_corners = False)
        #将input中对应位置的像素值填充到grid指定的位置，得到最终的输出。
        return batch_I_r.detach().numpy()
    
tps_transformation = TPS_SpatialTransformerNetwork(F=10, I_size=(256, 256), I_r_size=(256, 256), I_channel_num=3)

class HDF5Exporter:
    def __init__(self, h5_filename, h5_filename_line, h5_filename_gray, resolution, channels=3):
        rlog2 = int(np.floor(np.log2(resolution)))
        assert resolution == 2 ** rlog2
        self.resolution = resolution
        self.channels = channels
        
        self.h5_file = h5py.File(h5_filename, 'w')       
        self.h5_lods = []       
        self.buffers = []
        self.buffer_sizes = []
        
        self.h5_file_line = h5py.File(h5_filename_line, 'w')
        self.h5_lods_line = []
        self.buffers_line = []
        self.buffer_sizes_line = []
        
        self.h5_file_gray = h5py.File(h5_filename_gray, 'w')
        self.h5_lods_gray = []
        self.buffers_gray = []
        self.buffer_sizes_gray = []
        
        for lod in range(rlog2, -1, -1):
            #(-1,7]            
            c = channels
            c_line=1
            c_gray=3
            r = 2 ** lod            
            bytes_per_item = c * (r ** 2)#3*1*1,3*2*2......3*128*128
            chunk_size = int(np.ceil(128.0 / bytes_per_item))#1
            buffer_size = int(np.ceil(512.0 * np.exp2(20) / bytes_per_item))
            print(chunk_size,buffer_size)
                        
            lod = self.h5_file.create_dataset('data%dx%d' % (r,r), shape=(0,c,r,r), dtype=np.uint8,maxshape=(None,c,r,r), chunks=(chunk_size,c,r,r), compression='gzip', compression_opts=4)
            self.h5_lods.append(lod)            
            lod_line = self.h5_file_line.create_dataset('data%dx%d' % (r,r), shape=(0,c_line,r,r), dtype=np.uint8,maxshape=(None,c_line,r,r), chunks=(chunk_size,c_line,r,r), compression='gzip', compression_opts=4)            
            self.h5_lods_line.append(lod_line)            
            lod_gray = self.h5_file_gray.create_dataset('data%dx%d' % (r,r), shape=(0,c_gray,r,r), dtype=np.uint8,maxshape=(None,c_gray,r,r), chunks=(chunk_size,c_gray,r,r), compression='gzip', compression_opts=4)            
            self.h5_lods_gray.append(lod_gray)
            
            self.buffers.append(np.zeros((buffer_size,c,r,r), dtype=np.uint8))
            self.buffer_sizes.append(0)
            
            self.buffers_line.append(np.zeros((buffer_size,c_line,r,r), dtype=np.uint8))
            self.buffer_sizes_line.append(0)
            
            self.buffers_gray.append(np.zeros((buffer_size,c_gray,r,r), dtype=np.uint8))
            self.buffer_sizes_gray.append(0)
            
            #print(self.h5_lods,self.buffers,self.buffer_sizes)
            #[<HDF5 dataset "data128x128": shape (0, 3, 128, 128), type "|u1">, <HDF5 dataset "data64x64": shape (0, 3, 64, 64), type "|u1">, <HDF5 dataset "data32x32": shape (0, 3, 32, 32), type "|u1">, <HDF5 dataset "data16x16": shape (0, 3, 16, 16), type "|u1">, <HDF5 dataset "data8x8": shape (0, 3, 8, 8), type "|u1">, <HDF5 dataset "data4x4": shape (0, 3, 4, 4), type "|u1">, <HDF5 dataset "data2x2": shape (0, 3, 2, 2), type "|u1">]

    def close(self):
        for lod in range(len(self.h5_lods)):
            self.flush_lod(lod)
        self.h5_file.close()
        
        for lod_line in range(len(self.h5_lods_line)):
            self.flush_lod_line(lod_line)
        self.h5_file_line.close()
        
        for lod_gray in range(len(self.h5_lods_gray)):
            self.flush_lod_gray(lod_gray)
        self.h5_file_gray.close()

    def add_images(self, img):
        #assert img.ndim == 4 and img.shape[1] == self.channels and img.shape[2] == img.shape[3]
        #assert img.shape[2] >= self.resolution and img.shape[2] == 2 ** int(np.floor(np.log2(img.shape[2])))
        
        img_gray= tps_transformation(img)

        for lod in range(len(self.h5_lods)):
            lod_line=lod
            lod_gray=lod
            
            while img.shape[2] > self.resolution / (2 ** lod):
                img = img.astype(np.float32)                
                img = (img[:, :, 0::2, 0::2] + img[:, :, 0::2, 1::2] + img[:, :, 1::2, 0::2] + img[:, :, 1::2, 1::2]) * 0.25
            
            #while img_line.shape[2] > self.resolution / (2 ** lod_line):
                #img_line = img_line.astype(np.float32)                
                #img_line = (img_line[:, :, 0::2, 0::2] + img_line[:, :, 0::2, 1::2] + img_line[:, :, 1::2, 0::2] + img_line[:, :, 1::2, 1::2]) * 0.25
                
            while img_gray.shape[2] > self.resolution / (2 ** lod_gray):
                img_gray = img_gray.astype(np.float32)                
                img_gray = (img_gray[:, :, 0::2, 0::2] + img_gray[:, :, 0::2, 1::2] + img_gray[:, :, 1::2, 0::2] + img_gray[:, :, 1::2, 1::2]) * 0.25
            #print(img.shape, img_line.shape, img_gray.shape)
            img_line= main_line(img)[np.newaxis]
            quant = np.uint8(np.clip(np.round(img), 0, 255))#截断取整
            quant_line = np.uint8(np.clip(np.round(img_line), 0, 255))#截断取整
            quant_gray = np.uint8(np.clip(np.round(img_gray*255), 0, 255))#截断取整

            ofs = 0
            ofs_line=0
            ofs_gray=0
            
            while ofs < quant.shape[0]:
                num = min(quant.shape[0] - ofs, self.buffers[lod].shape[0] - self.buffer_sizes[lod])
                self.buffers[lod][self.buffer_sizes[lod] : self.buffer_sizes[lod] + num] = quant[ofs : ofs + num]
                self.buffer_sizes[lod] += num
                if self.buffer_sizes[lod] == self.buffers[lod].shape[0]:
                    self.flush_lod(lod)
                ofs += num
                
            while ofs_line < quant_line.shape[0]:
                num = min(quant_line.shape[0] - ofs_line, self.buffers_line[lod_line].shape[0] - self.buffer_sizes_line[lod_line])
                self.buffers_line[lod_line][self.buffer_sizes_line[lod_line] : self.buffer_sizes_line[lod_line] + num] = quant_line[ofs_line : ofs_line + num]
                self.buffer_sizes_line[lod_line] += num
                if self.buffer_sizes_line[lod_line] == self.buffers_line[lod_line].shape[0]:
                    self.flush_lod_line(lod_line)
                ofs_line += num
            
            while ofs_gray < quant_gray.shape[0]:
                num = min(quant_gray.shape[0] - ofs_gray, self.buffers_gray[lod_gray].shape[0] - self.buffer_sizes_gray[lod_gray])
                self.buffers_gray[lod_gray][self.buffer_sizes_gray[lod_gray] : self.buffer_sizes_gray[lod_gray] + num] = quant_gray[ofs_gray : ofs_gray + num]
                self.buffer_sizes_gray[lod_gray] += num
                if self.buffer_sizes_gray[lod_gray] == self.buffers_gray[lod_gray].shape[0]:
                    self.flush_lod_gray(lod_gray)
                ofs_gray += num

    def num_images(self):
        return self.h5_lods[0].shape[0] + self.buffer_sizes[0]
        
    def flush_lod(self, lod):
        num = self.buffer_sizes[lod]
        if num > 0:
            self.h5_lods[lod].resize(self.h5_lods[lod].shape[0] + num, axis=0)
            self.h5_lods[lod][-num:] = self.buffers[lod][:num]
            self.buffer_sizes[lod] = 0
            
    def flush_lod_line(self, lod_line):
        num = self.buffer_sizes_line[lod_line]
        if num > 0:
            self.h5_lods_line[lod_line].resize(self.h5_lods_line[lod_line].shape[0] + num, axis=0)          
            self.h5_lods_line[lod_line][-num:] = self.buffers_line[lod_line][:num]
            self.buffer_sizes_line[lod_line] = 0
            
    def flush_lod_gray(self, lod_gray):
        num = self.buffer_sizes_gray[lod_gray]
        if num > 0:
            self.h5_lods_gray[lod_gray].resize(self.h5_lods_gray[lod_gray].shape[0] + num, axis=0)          
            self.h5_lods_gray[lod_gray][-num:] = self.buffers_gray[lod_gray][:num]
            self.buffer_sizes_gray[lod_gray] = 0
            
###########################################################################
def create_celeba(h5_filename, h5_filename_line, h5_filename_gray, celeba_dir, cx):
    print('Creating CelebA dataset %s from %s' % (h5_filename, celeba_dir))
    num_images = cx
    h5 = HDF5Exporter(h5_filename, h5_filename_line, h5_filename_gray, 256, 3)
    for idx in range(num_images):
        print('%d / %d\r' % (idx, num_images))
        img = np.asarray(PIL.Image.open(celeba_dir + 'a (' + str(idx+1) + ')'+ '.jpg'))
        img = img.transpose(2, 0, 1) # HWC => CHW
        h5.add_images(img[np.newaxis])#np.newaxis的作用是增加一个维度。对于[: , np.newaxis] 和 [np.newaxis，：]是在np.newaxis这里增加1维。
        if idx%1000==0:
            print(idx)
    print('%-40s\r' % 'Flushing data...')
    h5.close()
    print('%-40s\r' % '')
    print('Added %d images.' % num_images)
########################################################################
create_celeba('D:/p.h5py','D:/l.h5py','D:/r.h5py','D:/256-selectbuilding/',100)
